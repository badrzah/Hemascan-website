# -*- coding: utf-8 -*-
"""HemascanModel.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mXoaX2HNzUEpNbVZmDwJT5qUPWcRq_v8
"""

!pip install --quiet torch torchvision torchaudio
!pip install --quiet numpy pandas scikit-learn matplotlib seaborn
!pip install --quiet pillow opencv-python
!pip install --quiet albumentations==1.4.8
!pip install --quiet torchmetrics==1.4.0.post0
!pip install --quiet tqdm
!pip install --quiet grad-cam==1.5.5
!pip install --quiet onnx onnxruntime
!pip install --quiet tensorboard

!pip install --quiet "albumentations==1.3.1"
!pip install --quiet opencv-python-headless==4.10.0.84

!unzip -q /content/data.zip -d /content/

import albumentations as A
from albumentations.pytorch import ToTensorV2
import cv2
print("✅ albumentations:", A.__version__)

import os, json, random, cv2
import numpy as np

import torch
import torch.nn as nn
from torch.utils.data import DataLoader, WeightedRandomSampler
from torchvision import datasets, models

from tqdm.auto import tqdm
from sklearn.metrics import classification_report, confusion_matrix
from torchmetrics.classification import (
    BinaryAUROC, BinaryAccuracy, BinaryF1Score, BinaryPrecision, BinaryRecall
)

import albumentations as A
from albumentations.pytorch import ToTensorV2

# ==========================================================================================================
SEED = 42
random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED); torch.cuda.manual_seed_all(SEED)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

IMG_SIZE = 224
BATCH    = 32
EPOCHS   = 12
LR       = 1e-4
WD       = 1e-4
MODEL_NAME = "resnet18"

DATA_TRAIN = "/content/data/train"
DATA_VAL   = "/content/data/val"
OUT_DIR    = "outputs"
os.makedirs(OUT_DIR, exist_ok=True)

#==================================================
train_tf = A.Compose([
    A.Resize(IMG_SIZE, IMG_SIZE),
    A.RandomBrightnessContrast(0.12, 0.12, p=0.5),
    A.HorizontalFlip(p=0.5),
    A.ShiftScaleRotate(shift_limit=0.02, scale_limit=0.1, rotate_limit=10,
                       border_mode=cv2.BORDER_REFLECT101, p=0.5),
    A.CLAHE(clip_limit=2.0, tile_grid_size=(8,8), p=0.2),
    A.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225)),
    ToTensorV2()
])
val_tf = A.Compose([
    A.Resize(IMG_SIZE, IMG_SIZE),
    A.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225)),
    ToTensorV2()
])

# ==================================================================================
class AlbumentationsImageFolder(torch.utils.data.Dataset):
    def __init__(self, root, transform):
        self.ds = datasets.ImageFolder(root)
        self.samples = self.ds.samples
        self.classes = self.ds.classes
        self.class_to_idx = self.ds.class_to_idx
        self.transform = transform
    def __len__(self): return len(self.samples)
    def __getitem__(self, idx):
        path, label = self.samples[idx]
        img = cv2.imread(path); img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        aug = self.transform(image=img)
        x = aug["image"]
        y = torch.tensor(label, dtype=torch.long)
        return x, y

train_ds = AlbumentationsImageFolder(DATA_TRAIN, train_tf)
val_ds   = AlbumentationsImageFolder(DATA_VAL,   val_tf)

#====================================================================================================================-
class_names = train_ds.classes
leuk_idx = train_ds.class_to_idx.get('leukemia', None)
norm_idx = train_ds.class_to_idx.get('normal', None)
assert leuk_idx is not None and norm_idx is not None, f"الفئات الموجودة: {class_names} (لازم يكون عندك 'leukemia' و 'normal')"
print("Classes/order:", class_names, "| leukemia_idx =", leuk_idx, "| normal_idx =", norm_idx)

# ================================================================================================================================
labels_list = [label for _, label in train_ds.samples]
counts = np.bincount(labels_list, minlength=len(class_names))
weights = 1.0 / np.maximum(counts, 1)
sample_weights = [weights[label] for _, label in train_ds.samples]
sampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True)

train_loader = DataLoader(train_ds, batch_size=BATCH, sampler=sampler, num_workers=2, pin_memory=True)
val_loader   = DataLoader(val_ds,   batch_size=BATCH, shuffle=False, num_workers=2, pin_memory=True)

print("Classes:", train_ds.classes, "| Train count:", counts.tolist())

# ============================ Model ============================
if MODEL_NAME == "resnet18":
    model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)
elif MODEL_NAME == "resnet50":
    model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V2)
else:
    raise ValueError("Unknown model")

num_classes = 2
in_features = model.fc.in_features
model.fc = nn.Linear(in_features, num_classes)
model = model.to(device)

criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WD)
scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)

# ================================================================================ Metrics
def init_metrics():
    return {
        "auroc": BinaryAUROC().to(device),
        "acc":   BinaryAccuracy().to(device),
        "f1":    BinaryF1Score().to(device),
        "prec":  BinaryPrecision().to(device),
        "rec":   BinaryRecall().to(device)
    }
def update_metrics(mets, probs, y_bin):
    mets["auroc"].update(probs, y_bin)
    mets["acc"].update(probs, y_bin)
    mets["f1"].update(probs, y_bin)
    mets["prec"].update(probs, y_bin)
    mets["rec"].update(probs, y_bin)
def compute_metrics(mets):
    out = {k: v.compute().item() for k, v in mets.items()}
    for v in mets.values(): v.reset()
    return out

# ======================== Training / Eval =======================
def run_epoch(loader, train=True):
    model.train(train)
    loss_sum, n = 0.0, 0
    mets = init_metrics()
    pbar = tqdm(loader, leave=False)
    for x, y in pbar:
        x, y = x.to(device), y.to(device)
        if train: optimizer.zero_grad()
        logits = model(x)
        loss = criterion(logits, y)
        if train:
            loss.backward(); optimizer.step()
        loss_sum += loss.item() * x.size(0); n += x.size(0)

        probs = torch.softmax(logits, dim=1)[:, leuk_idx]
        y_bin = (y == leuk_idx).long()
        update_metrics(mets, probs, y_bin)

    metrics = compute_metrics(mets)
    metrics["loss"] = loss_sum / n
    return metrics

best_auc, patience, wait = 0.0, 4, 0
history = []
for epoch in range(1, EPOCHS+1):
    tr = run_epoch(train_loader, True)
    va = run_epoch(val_loader,   False)
    scheduler.step()
    history.append({"epoch": epoch, "train": tr, "val": va})
    print(f"Epoch {epoch:02d} | TR loss {tr['loss']:.4f} | "
          f"VA loss {va['loss']:.4f} | AUC {va['auroc']:.4f} | "
          f"ACC {va['acc']:.4f} | F1 {va['f1']:.4f} | P {va['prec']:.4f} | R {va['rec']:.4f}")

    if va["auroc"] > best_auc + 1e-4:
        best_auc = va["auroc"]; wait = 0
        torch.save(model.state_dict(), os.path.join(OUT_DIR, "leukemia_best.pt"))
        print(" Saved best model")
    else:
        wait += 1
        if wait >= patience:
            print(" Early stopping."); break

# ======================== Final Report =========================
model.load_state_dict(torch.load(os.path.join(OUT_DIR,"leukemia_best.pt"), map_location=device))
model.eval()
all_probs, all_preds, all_labels = [], [], []
with torch.no_grad():
    for x, y in tqdm(val_loader, leave=False):
        x = x.to(device)
        logits = model(x)
        probs  = torch.softmax(logits, dim=1)[:, leuk_idx].cpu().numpy()
        preds  = logits.argmax(dim=1).cpu().numpy()
        labels = y.cpu().numpy()
        all_probs.extend(probs); all_preds.extend(preds); all_labels.extend(labels)

target_names = train_ds.classes
print("\n===== Classification Report =====")
print(classification_report(all_labels, all_preds, target_names=target_names))
print("===== Confusion Matrix =====")
print(confusion_matrix(all_labels, all_preds))

# ======================== Grad-CAM (اختياري) ===================
try:
    from pytorch_grad_cam import GradCAM
    from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget
    from pytorch_grad_cam.utils.image import show_cam_on_image

    def denorm(batch):
        mean = torch.tensor([0.485,0.456,0.406], device=batch.device).view(1,3,1,1)
        std  = torch.tensor([0.229,0.224,0.225], device=batch.device).view(1,3,1,1)
        return torch.clamp(batch*std + mean, 0, 1)

    model.eval()
    sample_loader = DataLoader(val_ds, batch_size=1, shuffle=True)
    x0, y0 = next(iter(sample_loader))
    x0 = x0.to(device)
    target_layer = model.layer4[-1]
    with GradCAM(model=model, target_layers=[target_layer]) as cam:
        with torch.no_grad():
            logits = model(x0)
        pred = int(torch.argmax(logits, dim=1).item())
        grayscale_cam = cam(input_tensor=x0, targets=[ClassifierOutputTarget(pred)])[0]

    rgb_img = denorm(x0).squeeze(0).permute(1,2,0).cpu().numpy()
    vis = show_cam_on_image(rgb_img, grayscale_cam, use_rgb=True)
    cv2.imwrite(os.path.join(OUT_DIR, "gradcam_sample.png"), cv2.cvtColor(vis, cv2.COLOR_RGB2BGR))
    print(" Saved Grad-CAM -> outputs/gradcam_sample.png")
except Exception as e:
    print(" Grad-CAM skipped:", e)

# ======================== Export TorchScript (.pt) ==============
# (استبدلنا تصدير ONNX بهذا القسم)
TS_OUT = os.path.join(OUT_DIR, "leukemia_torchscript.pt")

# نحول المودل إلى CPU قبل التتبع (أضمن للتوافق)
model_cpu = model.to("cpu").eval()
dummy = torch.randn(1, 3, IMG_SIZE, IMG_SIZE, device="cpu")
with torch.no_grad():
    ts_model = torch.jit.trace(model_cpu, dummy)
ts_model.save(TS_OUT)
print("✅ Saved TorchScript ->", TS_OUT)

# ======================== Save config ===========================
cfg = {
    "img_size": IMG_SIZE,
    "mean": [0.485,0.456,0.406],
    "std": [0.229,0.224,0.225],
    "classes": class_names,
    "model_name": MODEL_NAME,
    "leukemia_index": int(leuk_idx),
    "normal_index": int(norm_idx)
}
with open(os.path.join(OUT_DIR,"config.json"), "w") as f:
    json.dump(cfg, f, indent=2)
print("✅ Saved config -> outputs/config.json")

